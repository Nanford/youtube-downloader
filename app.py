#!/usr/bin/env python3
"""
YouTube ä¸‹è½½å™¨ - ä¿®å¤ç‰ˆ
é€‚ç”¨äº yt.leenf.online
"""

import os
import sys
import subprocess
import threading
import json
import time
import datetime
import uuid
import logging
import re
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_from_directory
from flask_socketio import SocketIO, emit, join_room, leave_room
from werkzeug.utils import secure_filename
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®ç±»
class Config:
    SECRET_KEY = os.getenv('SECRET_KEY', os.urandom(24).hex())
    DEBUG = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    DOMAIN = os.getenv('DOMAIN', 'yt.leenf.online')
    HOST = os.getenv('HOST', '0.0.0.0')
    PORT = int(os.getenv('PORT', 8091))
    
    # ç›®å½•é…ç½®
    BASE_DIR = Path(__file__).parent
    DOWNLOAD_DIR = Path(os.getenv('DOWNLOAD_DIR', BASE_DIR / 'downloads'))
    UPLOAD_DIR = Path(os.getenv('UPLOAD_DIR', BASE_DIR / 'uploads'))
    LOG_DIR = Path(os.getenv('LOG_DIR', BASE_DIR / 'logs'))
    
    # æ–‡ä»¶é…ç½® - ğŸ”§ åŠ å¼ºå®‰å…¨é™åˆ¶
    MAX_CONTENT_LENGTH = int(os.getenv('MAX_CONTENT_LENGTH', 1 * 1024 * 1024))  # 1MB
    MAX_COOKIES_FILE_SIZE = int(os.getenv('MAX_COOKIES_FILE_SIZE', 100 * 1024))  # 100KB
    MAX_CONCURRENT_DOWNLOADS = int(os.getenv('MAX_CONCURRENT_DOWNLOADS', 2))  # é™ä½å¹¶å‘æ•°
    DOWNLOAD_TIMEOUT = int(os.getenv('DOWNLOAD_TIMEOUT', 1800))
    
    def __init__(self):
        # åˆ›å»ºå¿…è¦ç›®å½•
        for directory in [self.DOWNLOAD_DIR, self.UPLOAD_DIR, self.LOG_DIR]:
            directory.mkdir(parents=True, exist_ok=True)

config = Config()

# åˆ›å»º Flask åº”ç”¨
app = Flask(__name__)
app.config.from_object(config)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]',
    handlers=[
        logging.FileHandler(config.LOG_DIR / 'app.log'),
        logging.StreamHandler()
    ]
)

if not config.DEBUG:
    file_handler = logging.FileHandler(config.LOG_DIR / 'app.log')
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
    ))
    file_handler.setLevel(logging.INFO)
    app.logger.addHandler(file_handler)
    app.logger.setLevel(logging.INFO)

# ğŸ”§ å®‰å…¨å‡½æ•°
def sanitize_log_message(message):
    """æ¸…ç†æ—¥å¿—æ¶ˆæ¯ï¼Œé˜²æ­¢æ³¨å…¥"""
    if not isinstance(message, str):
        message = str(message)
    # ç§»é™¤æ½œåœ¨å±é™©å­—ç¬¦
    message = re.sub(r'[<>"\'\\\x00-\x1f\x7f-\x9f]', '', message)
    # é™åˆ¶é•¿åº¦
    if len(message) > 500:
        message = message[:497] + "..."
    return message

def validate_session_id(session_id):
    """éªŒè¯ä¼šè¯IDæ ¼å¼"""
    if not session_id:
        return False
    # å…è®¸UUIDæ ¼å¼æˆ–32ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²
    pattern = r'^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$|^[a-f0-9]{32}$'
    return bool(re.match(pattern, session_id))

def validate_url(url):
    """éªŒè¯URLæ˜¯å¦ä¸ºæœ‰æ•ˆçš„YouTubeé“¾æ¥"""
    if not url or len(url) > 500:
        return False
    youtube_patterns = [
        r'https?://(?:www\.)?youtube\.com/watch\?v=[\w-]+',
        r'https?://(?:www\.)?youtube\.com/shorts/[\w-]+',
        r'https?://youtu\.be/[\w-]+',
        r'https?://(?:www\.)?youtube\.com/playlist\?list=[\w-]+',
        r'https?://(?:www\.)?youtube\.com/channel/[\w-]+',
        r'https?://(?:www\.)?youtube\.com/@[\w-]+',
    ]
    return any(re.match(pattern, url) for pattern in youtube_patterns)

# ç”¨æˆ·ä¼šè¯ç±»
class UserSession:
    def __init__(self, session_id):
        self.session_id = session_id
        self.created_at = datetime.datetime.now()
        self.last_activity = datetime.datetime.now()
        self.download_manager = None
        
    def update_activity(self):
        """æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´"""
        self.last_activity = datetime.datetime.now()
        
    def get_cookies_path(self):
        return config.UPLOAD_DIR / f"cookies_{self.session_id}.txt"
    
    def get_download_dir(self):
        download_dir = config.DOWNLOAD_DIR / f"session_{self.session_id}"
        download_dir.mkdir(exist_ok=True)
        return download_dir

# å…¨å±€ä¼šè¯å­˜å‚¨
user_sessions = {}

def get_or_create_session():
    """è·å–æˆ–åˆ›å»ºç”¨æˆ·ä¼šè¯"""
    session_id = request.headers.get('X-Session-ID')
    
    # éªŒè¯ç°æœ‰ä¼šè¯ID
    if session_id and validate_session_id(session_id) and session_id in user_sessions:
        user_sessions[session_id].update_activity()
        return user_sessions[session_id], session_id
    
    # åˆ›å»ºæ–°ä¼šè¯
    session_id = str(uuid.uuid4())
    user_sessions[session_id] = UserSession(session_id)
    return user_sessions[session_id], session_id

# Cookies ç®¡ç†å™¨
class CookiesManager:
    def __init__(self, session_id):
        self.session_id = session_id
        self.cookies_file = config.UPLOAD_DIR / f"cookies_{session_id}.txt"
    
    def check_cookies_exist(self):
        return self.cookies_file.exists()
    
    def get_cookies_age_days(self):
        if not self.check_cookies_exist():
            return None
        mtime = self.cookies_file.stat().st_mtime
        age_seconds = time.time() - mtime
        return int(age_seconds / 86400)
    
    def validate_cookies_file(self, content):
        """ğŸ”§ å¢å¼ºçš„ cookies æ–‡ä»¶éªŒè¯"""
        try:
            # æ£€æŸ¥å†…å®¹é•¿åº¦
            if len(content) > config.MAX_COOKIES_FILE_SIZE:
                return False, "Cookies æ–‡ä»¶è¿‡å¤§"
            
            if len(content.strip()) < 50:
                return False, "Cookies æ–‡ä»¶å†…å®¹è¿‡å°‘"
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©å†…å®¹
            dangerous_patterns = [
                r'<script[^>]*>',
                r'javascript:',
                r'data:',
                r'vbscript:',
                r'onload=',
                r'onerror=',
            ]
            
            content_lower = content.lower()
            for pattern in dangerous_patterns:
                if re.search(pattern, content_lower):
                    return False, "æ–‡ä»¶å†…å®¹åŒ…å«æ½œåœ¨å±é™©ä»£ç "
            
            lines = content.strip().split('\n')
            valid_lines = [line for line in lines if line.strip() and not line.startswith('#')]
            
            if len(valid_lines) < 5:
                return False, "Cookies æ–‡ä»¶å†…å®¹è¿‡å°‘"
            
            # æ£€æŸ¥å…³é”® cookies - æ›´å®½æ¾çš„æ£€æŸ¥
            youtube_indicators = ['youtube', 'google', 'VISITOR_INFO', 'YSC', 'CONSENT', 'PREF', 'SID']
            found_indicators = sum(1 for indicator in youtube_indicators if indicator in content)
            
            if found_indicators < 2:
                return False, "ç¼ºå°‘å…³é”® YouTube cookies"
            
            # éªŒè¯cookiesæ ¼å¼ï¼ˆNetscapeæ ¼å¼ï¼‰
            valid_cookie_lines = 0
            for line in valid_lines[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
                parts = line.split('\t')
                if len(parts) >= 6:  # Netscapeæ ¼å¼è‡³å°‘6ä¸ªå­—æ®µ
                    valid_cookie_lines += 1
            
            if valid_cookie_lines < 3:
                return False, "Cookies æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼ˆåº”ä¸º Netscape æ ¼å¼ï¼‰"
            
            return True, "Cookies æ–‡ä»¶æ ¼å¼æ­£ç¡®"
            
        except Exception as e:
            app.logger.error(f"Cookies validation error: {str(e)}")
            return False, f"éªŒè¯å¤±è´¥: æ–‡ä»¶æ ¼å¼é”™è¯¯"
    
    def save_cookies(self, content):
        """ğŸ”§ å®‰å…¨çš„ cookies ä¿å­˜"""
        is_valid, message = self.validate_cookies_file(content)
        if not is_valid:
            return False, message
        
        try:
            # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœå·²å­˜åœ¨ï¼‰
            if self.cookies_file.exists():
                backup_file = self.cookies_file.with_suffix('.bak')
                self.cookies_file.rename(backup_file)
            
            # å®‰å…¨å†™å…¥
            with open(self.cookies_file, 'w', encoding='utf-8', newline='\n') as f:
                f.write(content)
            
            # è®¾ç½®æ–‡ä»¶æƒé™ï¼ˆåªæœ‰æ‰€æœ‰è€…å¯è¯»å†™ï¼‰
            self.cookies_file.chmod(0o600)
            
            app.logger.info(f"Cookies saved for session {self.session_id[:8]}")
            return True, "Cookies ä¿å­˜æˆåŠŸ"
            
        except Exception as e:
            app.logger.error(f"Failed to save cookies: {str(e)}")
            return False, f"ä¿å­˜å¤±è´¥: {str(e)}"
    
    def should_update_cookies(self):
        if not self.check_cookies_exist():
            return True, "âŒ æœªä¸Šä¼  cookies æ–‡ä»¶"
        
        age = self.get_cookies_age_days()
        if age and age > 30:
            return True, f"â° Cookies å·²ä½¿ç”¨ {age} å¤©ï¼Œå»ºè®®æ›´æ–°"
        
        return False, f"âœ… Cookies çŠ¶æ€è‰¯å¥½ï¼ˆ{age or 0} å¤©å‰ä¸Šä¼ ï¼‰"

# ä¸‹è½½ç®¡ç†å™¨
class DownloadManager:
    def __init__(self, session_id):
        self.session_id = session_id
        self.room = f"session_{session_id}"
        self.is_downloading = False
        self.current_progress = {"current": 0, "total": 0, "status": "idle"}
        self.cookies_manager = CookiesManager(session_id)
        self.download_count = 0  # ä¸‹è½½è®¡æ•°
        self.start_time = None
    
    def log_message(self, message):
        safe_message = sanitize_log_message(message)
        app.logger.info(f"[{self.session_id[:8]}] {safe_message}")
        socketio.emit('log_message', {'message': safe_message}, room=self.room)
    
    def update_progress(self, current, total, status="downloading"):
        self.current_progress = {
            "current": current,
            "total": total,
            "status": status,
            "percentage": int((current / total) * 100) if total > 0 else 0
        }
        socketio.emit('progress_update', self.current_progress, room=self.room)
    
    def check_ffmpeg(self):
        """æ£€æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False
    
    def get_download_options(self):
        """ğŸ”§ è·å–å®‰å…¨çš„ä¸‹è½½é€‰é¡¹"""
        has_ffmpeg = self.check_ffmpeg()
        
        base_opts = [
            "-o", "%(title).100s.%(ext)s",  # é™åˆ¶æ–‡ä»¶åé•¿åº¦
            "--embed-metadata",
            "--no-warnings",
            "--user-agent", "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36",
            "--referer", "https://www.youtube.com/",
            "--extractor-retries", "2",  # å‡å°‘é‡è¯•æ¬¡æ•°
            "--fragment-retries", "2",
            "--retry-sleep", "exp=1:3",  # å‡å°‘é‡è¯•é—´éš”
            "--socket-timeout", "30",
            "--max-filesize", "500M",  # ğŸ”§ æ·»åŠ æ–‡ä»¶å¤§å°é™åˆ¶
            "--max-duration", "3600",  # ğŸ”§ æ·»åŠ æ—¶é•¿é™åˆ¶ï¼ˆ1å°æ—¶ï¼‰
            "--no-playlist",  # ğŸ”§ ç¦æ­¢ä¸‹è½½æ’­æ”¾åˆ—è¡¨
        ]
        
        if has_ffmpeg:
            base_opts.extend(["-f", "bv*[height<=720]+ba/b[height<=720]"])  # ğŸ”§ é™åˆ¶åˆ†è¾¨ç‡
            self.log_message("ğŸ¬ ä½¿ç”¨ FFmpeg é«˜ç”»è´¨æ¨¡å¼ï¼ˆ720pé™åˆ¶ï¼‰")
        else:
            base_opts.extend(["-f", "best[height<=720]/best"])  # ğŸ”§ é™åˆ¶åˆ†è¾¨ç‡
            self.log_message("ğŸ“± ä½¿ç”¨å…¼å®¹æ¨¡å¼ï¼ˆ720pé™åˆ¶ï¼‰")
        
        # æ·»åŠ  cookies
        if self.cookies_manager.check_cookies_exist():
            base_opts.extend(["--cookies", str(self.cookies_manager.cookies_file)])
            age = self.cookies_manager.get_cookies_age_days()
            self.log_message(f"ğŸª ä½¿ç”¨ cookies æ–‡ä»¶ï¼ˆ{age}å¤©å‰ä¸Šä¼ ï¼‰")
        
        return base_opts
    
    def validate_urls(self, urls):
        """ğŸ”§ éªŒè¯URLåˆ—è¡¨"""
        if len(urls) > 5:  # é™åˆ¶æ‰¹é‡ä¸‹è½½æ•°é‡
            return False, "å•æ¬¡æœ€å¤šä¸‹è½½5ä¸ªè§†é¢‘"
        
        valid_urls = []
        for url in urls:
            if not validate_url(url):
                return False, f"æ— æ•ˆçš„URL: {url[:50]}..."
            valid_urls.append(url)
        
        return True, valid_urls
    
    def download_video(self, url, download_dir):
        """ğŸ”§ å®‰å…¨çš„è§†é¢‘ä¸‹è½½"""
        self.log_message(f"ğŸ¬ å¼€å§‹ä¸‹è½½: {url[:50]}...")
        
        cmd = [sys.executable, "-m", "yt_dlp"] + self.get_download_options()
        cmd.extend(["-P", str(download_dir), url])
        
        try:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                universal_newlines=True
            )
            
            # è®¾ç½®è¶…æ—¶
            timeout = 600  # 10åˆ†é’Ÿè¶…æ—¶
            start_time = time.time()
            
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                    
                # æ£€æŸ¥è¶…æ—¶
                if time.time() - start_time > timeout:
                    process.terminate()
                    self.log_message("â° ä¸‹è½½è¶…æ—¶ï¼Œå·²ç»ˆæ­¢")
                    return False
                    
                if output:
                    clean_output = output.strip()
                    if clean_output and not clean_output.startswith('['):
                        # åªæ˜¾ç¤ºé‡è¦ä¿¡æ¯
                        if any(keyword in clean_output.lower() for keyword in 
                               ['downloading', 'finished', 'error', 'warning']):
                            self.log_message(f"ğŸ“¥ {clean_output[:100]}...")
            
            if process.returncode == 0:
                self.log_message(f"âœ… ä¸‹è½½å®Œæˆ: {url[:30]}...")
                return True
            else:
                error = process.stderr.read().strip()
                if "Sign in to confirm" in error:
                    self.log_message("ğŸ¤– æ£€æµ‹åˆ°åæœºå™¨äººä¿æŠ¤ï¼Œè¯·æ›´æ–° cookies")
                elif "Private video" in error:
                    self.log_message("ğŸ”’ ç§æœ‰è§†é¢‘ï¼Œæ— æ³•ä¸‹è½½")
                elif "Video unavailable" in error:
                    self.log_message("ğŸ“¹ è§†é¢‘ä¸å¯ç”¨")
                else:
                    self.log_message(f"âŒ ä¸‹è½½å¤±è´¥: {error[:100]}...")
                return False
                
        except Exception as e:
            self.log_message(f"âŒ ä¸‹è½½å¼‚å¸¸: {str(e)[:100]}...")
            return False
    
    def batch_download(self, urls):
        """ğŸ”§ å®‰å…¨çš„æ‰¹é‡ä¸‹è½½"""
        if self.is_downloading:
            self.log_message("âš ï¸ æ­£åœ¨ä¸‹è½½ä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ...")
            return
        
        # éªŒè¯URLs
        is_valid, result = self.validate_urls(urls)
        if not is_valid:
            self.log_message(f"âŒ URLéªŒè¯å¤±è´¥: {result}")
            return
        
        urls = result
        self.is_downloading = True
        self.start_time = time.time()
        session = user_sessions[self.session_id]
        download_dir = session.get_download_dir()
        
        self.log_message(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½ï¼Œå…± {len(urls)} ä¸ªè§†é¢‘")
        self.update_progress(0, len(urls), "starting")
        
        success_count = 0
        for i, url in enumerate(urls, 1):
            self.update_progress(i-1, len(urls), "downloading")
            self.log_message(f"ğŸ“‹ [{i}/{len(urls)}] å¤„ç†: {url[:50]}...")
            
            if self.download_video(url, download_dir):
                success_count += 1
                self.download_count += 1
            
            # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¢«åçˆ¬è™«
            time.sleep(2)
        
        elapsed_time = int(time.time() - self.start_time)
        self.update_progress(len(urls), len(urls), "completed")
        self.log_message(f"ğŸ‰ æ‰¹é‡ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count}/{len(urls)} ç”¨æ—¶: {elapsed_time}ç§’")
        self.is_downloading = False

# Flask è·¯ç”±
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload_cookies', methods=['POST'])
def upload_cookies():
    """ğŸ”§ ä¿®å¤åçš„ä¸Šä¼  cookies æ–‡ä»¶"""
    try:
        session, session_id = get_or_create_session()
        
        # æ£€æŸ¥è¯·æ±‚
        if 'cookies_file' not in request.files:
            app.logger.warning(f"No file in upload request from {request.remote_addr}")
            return jsonify({"error": "æ²¡æœ‰æ–‡ä»¶ä¸Šä¼ "}), 400
        
        file = request.files['cookies_file']
        if file.filename == '':
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400
        
        # å®‰å…¨æ–‡ä»¶å
        filename = secure_filename(file.filename)
        if not filename.lower().endswith('.txt'):
            return jsonify({"error": "åªæ”¯æŒ .txt æ–‡ä»¶"}), 400
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
        file_size = file.tell()
        file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
        
        if file_size > config.MAX_COOKIES_FILE_SIZE:
            return jsonify({"error": f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {config.MAX_COOKIES_FILE_SIZE//1024}KB"}), 400
        
        if file_size == 0:
            return jsonify({"error": "æ–‡ä»¶ä¸ºç©º"}), 400
        
        try:
            content = file.read().decode('utf-8')
        except UnicodeDecodeError:
            return jsonify({"error": "æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ä½¿ç”¨UTF-8ç¼–ç "}), 400
        
        # éªŒè¯å’Œä¿å­˜
        cookies_manager = CookiesManager(session_id)
        success, message = cookies_manager.save_cookies(content)
        
        if success:
            app.logger.info(f"Cookies uploaded successfully for session {session_id[:8]} from {request.remote_addr}")
            # ğŸ”§ ç¡®ä¿è¿”å›æ­£ç¡®çš„æ ¼å¼
            return jsonify({
                "message": message,
                "session_id": session_id,
                "success": True  # ğŸ”§ æ·»åŠ successå­—æ®µä»¥å…¼å®¹å‰ç«¯
            })
        else:
            app.logger.warning(f"Cookies upload failed for session {session_id[:8]}: {message}")
            return jsonify({"error": message}), 400
            
    except Exception as e:
        app.logger.error(f"Cookies upload error: {str(e)}")
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

@app.route('/api/download', methods=['POST'])
def api_download():
    """ğŸ”§ æ”¹è¿›çš„ä¸‹è½½ API"""
    try:
        session, session_id = get_or_create_session()
        
        if not session.download_manager:
            session.download_manager = DownloadManager(session_id)
        
        data = request.get_json()
        if not data:
            return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
            
        urls = data.get('urls', [])
        
        if not urls:
            return jsonify({"error": "æ²¡æœ‰æä¾›æœ‰æ•ˆçš„ URL"}), 400
        
        # ğŸ”§ å¢å¼ºURLéªŒè¯
        valid_urls = []
        for url in urls:
            url = url.strip()
            if validate_url(url):
                valid_urls.append(url)
        
        if not valid_urls:
            return jsonify({"error": "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ YouTube URL"}), 400
        
        if len(valid_urls) > 5:  # ğŸ”§ é™åˆ¶æ•°é‡
            return jsonify({"error": "å•æ¬¡æœ€å¤šä¸‹è½½5ä¸ªè§†é¢‘"}), 400
        
        # ğŸ”§ æ£€æŸ¥ä¸‹è½½é¢‘ç‡
        if session.download_manager.download_count > 20:  # æ¯æ—¥é™åˆ¶
            return jsonify({"error": "ä»Šæ—¥ä¸‹è½½æ¬¡æ•°å·²è¾¾ä¸Šé™"}), 429
        
        threading.Thread(
            target=session.download_manager.batch_download,
            args=(valid_urls,),
            daemon=True
        ).start()
        
        app.logger.info(f"Download started for session {session_id[:8]}: {len(valid_urls)} URLs")
        return jsonify({
            "message": f"å¼€å§‹ä¸‹è½½ {len(valid_urls)} ä¸ªè§†é¢‘",
            "session_id": session_id
        })
        
    except Exception as e:
        app.logger.error(f"Download API error: {str(e)}")
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

@app.route('/api/status')
def api_status():
    """ğŸ”§ æ”¹è¿›çš„çŠ¶æ€ API"""
    try:
        session, session_id = get_or_create_session()
        
        if not session.download_manager:
            session.download_manager = DownloadManager(session_id)
        
        should_update, message = session.download_manager.cookies_manager.should_update_cookies()
        
        return jsonify({
            "session_id": session_id,
            "is_downloading": session.download_manager.is_downloading,
            "progress": session.download_manager.current_progress,
            "cookies": {
                "exists": session.download_manager.cookies_manager.check_cookies_exist(),
                "should_update": should_update,
                "status_message": message
            },
            "ffmpeg_available": session.download_manager.check_ffmpeg(),
            "download_count": session.download_manager.download_count
        })
        
    except Exception as e:
        app.logger.error(f"Status API error: {str(e)}")
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

@app.route('/downloads/<session_id>')
def download_files(session_id):
    """ğŸ”§ å®‰å…¨çš„æ–‡ä»¶åˆ—è¡¨"""
    try:
        # éªŒè¯ä¼šè¯ID
        if not validate_session_id(session_id) or session_id not in user_sessions:
            return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404
        
        session = user_sessions[session_id]
        download_dir = session.get_download_dir()
        
        files = []
        try:
            for file_path in download_dir.iterdir():
                if file_path.is_file() and file_path.stat().st_size > 0:
                    # ğŸ”§ å®‰å…¨çš„æ–‡ä»¶åå¤„ç†
                    safe_name = secure_filename(file_path.name)
                    files.append({
                        "name": safe_name,
                        "size": file_path.stat().st_size,
                        "url": f"/download_file/{session_id}/{safe_name}",
                        "modified": file_path.stat().st_mtime
                    })
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            files.sort(key=lambda x: x['modified'], reverse=True)
            
        except PermissionError:
            app.logger.error(f"Permission denied accessing download dir for session {session_id}")
            return jsonify({"error": "è®¿é—®æƒé™ä¸è¶³"}), 403
        
        return jsonify({"files": files})
        
    except Exception as e:
        app.logger.error(f"Download files error: {str(e)}")
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

@app.route('/download_file/<session_id>/<filename>')
def download_file(session_id, filename):
    """ğŸ”§ å®‰å…¨çš„æ–‡ä»¶ä¸‹è½½"""
    try:
        # éªŒè¯ä¼šè¯ID
        if not validate_session_id(session_id) or session_id not in user_sessions:
            return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404
        
        # ğŸ”§ å®‰å…¨æ–‡ä»¶åå¤„ç†
        safe_filename = secure_filename(filename)
        if not safe_filename or safe_filename != filename:
            return jsonify({"error": "æ— æ•ˆçš„æ–‡ä»¶å"}), 400
        
        session = user_sessions[session_id]
        download_dir = session.get_download_dir()
        file_path = download_dir / safe_filename
        
        # ğŸ”§ æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”åœ¨æ­£ç¡®ç›®å½•ä¸­
        if not file_path.exists() or not str(file_path).startswith(str(download_dir)):
            return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        return send_from_directory(download_dir, safe_filename, as_attachment=True)
        
    except Exception as e:
        app.logger.error(f"Download file error: {str(e)}")
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

@socketio.on('connect')
def handle_connect():
    try:
        session, session_id = get_or_create_session()
        join_room(f"session_{session_id}")
        emit('connected', {'session_id': session_id})
        app.logger.info(f"Client connected: session {session_id[:8]}")
    except Exception as e:
        app.logger.error(f"Socket connect error: {str(e)}")

@socketio.on('disconnect')
def handle_disconnect():
    try:
        session, session_id = get_or_create_session()
        leave_room(f"session_{session_id}")
        app.logger.info(f"Client disconnected: session {session_id[:8]}")
    except Exception as e:
        app.logger.error(f"Socket disconnect error: {str(e)}")

# ğŸ”§ æ¸…ç†ä»»åŠ¡
def cleanup_old_sessions():
    """æ¸…ç†æ—§ä¼šè¯å’Œæ–‡ä»¶"""
    try:
        cutoff_time = datetime.datetime.now() - datetime.timedelta(hours=24)
        to_remove = []
        
        for sid, session in user_sessions.items():
            if session.last_activity < cutoff_time:
                to_remove.append(sid)
                
                # æ¸…ç†æ–‡ä»¶
                try:
                    cookies_file = session.get_cookies_path()
                    if cookies_file.exists():
                        cookies_file.unlink()
                    
                    download_dir = session.get_download_dir()
                    if download_dir.exists():
                        # åˆ é™¤æ—§æ–‡ä»¶
                        for file_path in download_dir.iterdir():
                            if file_path.is_file():
                                file_age = time.time() - file_path.stat().st_mtime
                                if file_age > 86400:  # 1å¤©
                                    file_path.unlink()
                        
                        # å¦‚æœç›®å½•ä¸ºç©ºåˆ™åˆ é™¤
                        if not list(download_dir.iterdir()):
                            download_dir.rmdir()
                            
                except Exception as e:
                    app.logger.error(f"Error cleaning session {sid}: {str(e)}")
        
        for session_id in to_remove:
            del user_sessions[session_id]
        
        if to_remove:
            app.logger.info(f"æ¸…ç†äº† {len(to_remove)} ä¸ªè¿‡æœŸä¼šè¯")
            
    except Exception as e:
        app.logger.error(f"Cleanup error: {str(e)}")

def start_cleanup_task():
    def cleanup_loop():
        while True:
            time.sleep(3600)  # æ¯å°æ—¶æ¸…ç†
            cleanup_old_sessions()
    
    threading.Thread(target=cleanup_loop, daemon=True).start()

# ğŸ”§ é”™è¯¯å¤„ç†
@app.errorhandler(413)
def request_entity_too_large(error):
    return jsonify({"error": "ä¸Šä¼ æ–‡ä»¶è¿‡å¤§"}), 413

@app.errorhandler(500)
def internal_error(error):
    app.logger.error(f"Internal error: {str(error)}")
    return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500

@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "é¡µé¢ä¸å­˜åœ¨"}), 404

if __name__ == '__main__':
    start_cleanup_task()
    app.logger.info(f"ğŸš€ å¯åŠ¨ YouTube ä¸‹è½½å™¨ - {config.DOMAIN}")
    socketio.run(app, debug=config.DEBUG, host=config.HOST, port=config.PORT)